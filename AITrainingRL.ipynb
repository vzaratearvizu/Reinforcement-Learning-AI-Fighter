{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9549aefa-fdbb-4c63-b151-b750f418680d",
   "metadata": {},
   "source": [
    "| Keyboard key | GameBoy equivalant |\n",
    "| ---          | ---                |\n",
    "| Up           | Up                 |\n",
    "| Down         | Down               |\n",
    "| Left         | Left               |\n",
    "| Right        | Right              |\n",
    "| A            | A                  |\n",
    "| S            | B                  |\n",
    "| Return       | Start              |\n",
    "| Backspace    | Select             |\n",
    "\n",
    "| Keyboard key | Emulator function       |\n",
    "| ---          | ---                     |\n",
    "| F11          | Toggle fullscreen       |\n",
    "| Escape       | Quit                    |\n",
    "| D            | Debug                   |\n",
    "| Space        | Unlimited FPS           |\n",
    "| Z            | Save state              |\n",
    "| X            | Load state              |\n",
    "| I            | Toggle screen recording |\n",
    "| O            | Save screenshot         |\n",
    "| ,            | Rewind backwards        |\n",
    "| .            | Rewind forward          |\n",
    "| J            | Memory Window + 0x100   |\n",
    "| K            | Memory Window - 0x100   |\n",
    "| Shift + J    | Memory Window + 0x1000  |\n",
    "| Shift + K    | Memory Window - 0x1000  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047b933b-c6cc-4397-9afb-adcc42d7e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous training: {0: [14.17944228557316, 12.006324421353902, 21.717196924876124, 6.5597068877220766], 1: [6.5187805169679836, 6.606340524463887, 7.857512069241469, 6.59339578953752], 2: [3.060889393479474, 5.008312451840862, 4.24176287379106, 2.664607044180602]}\n",
      "Match: 3 | Round: 2 | Timer: 74 | P1 Health:   0 | P2 Health:   0 | P1 Distance: 154 | P2 Distance: 682"
     ]
    }
   ],
   "source": [
    "# Just The Imports\n",
    "from pyboy import PyBoy\n",
    "import random\n",
    "import threading\n",
    "import json\n",
    "import os\n",
    "pyboy = PyBoy(r\"rompath\")\n",
    "\n",
    "# Mutes The Sound. I Want To Listen To My Own Music While Running This\n",
    "pyboy.memory[0xFF26] = 0x00  # NR52 - Sound on/off\n",
    "pyboy.memory[0xFF24] = 0x00  # NR50 - Channel control / volume\n",
    "pyboy.memory[0xFF25] = 0x00  # NR51 - Sound panning\n",
    "\n",
    "# Round Timer Starting From 99\n",
    "TIMER_CHANNEL = 0xcbb3\n",
    "\n",
    "# Player Health\n",
    "P1_HEALTH_CHANNEL = 0xc4b5\n",
    "P2_HEALTH_CHANNEL = 0xc6b5\n",
    "\n",
    "# Player Distances\n",
    "P1_DISTANCE_CHANNEL = 0xc40e\n",
    "P2_DISTANCE_CHANNEL = 0xc60e\n",
    "\n",
    "# Just Figures Out What The Current Distance Is\n",
    "def get_game_state():\n",
    "    # Gets PLayer Position\n",
    "    p1_pos = pyboy.memory[P1_DISTANCE_CHANNEL]\n",
    "    p2_pos = pyboy.memory[P2_DISTANCE_CHANNEL]\n",
    "\n",
    "    # Handles Cases Where Distance Changes Abnormally When In Close Distance\n",
    "    # When A Player Gets Too Close, The Game Sometimes Adds The Ones Place In The Number Again, Turning It Into A Hundreds Number. Ex: 48 --> 488\n",
    "    if p1_pos > 200:\n",
    "        p1_pos = p1_pos // 10\n",
    "    if p2_pos > 200:\n",
    "        p2_pos = p2_pos // 10\n",
    "\n",
    "    # Finds The Distance Between The Players\n",
    "    distance = abs(p1_pos - p2_pos)\n",
    "\n",
    "    # Classified Range Distances I Made Up\n",
    "    # Close - Determined By Farthest Point A Hit Could Register\n",
    "    if distance < 62:\n",
    "        return 0\n",
    "    # Medium\n",
    "    elif distance < 101:\n",
    "        return 1\n",
    "    # Far\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def load_q_table():\n",
    "    if os.path.exists('q_table.json'):\n",
    "        try:\n",
    "            # with Opens The File And Closes The File Once Done\n",
    "            # 'r' means Read Mode. \n",
    "            with open('q_table.json', 'r') as table_file:\n",
    "                data = json.load(table_file)\n",
    "                q_table = {}\n",
    "                for key, value in data.items():\n",
    "                    q_table[int(key)] = value\n",
    "                return q_table\n",
    "        except:\n",
    "            print('Failed to load previously trained data. Starting with an empty q_table')\n",
    "            return {}\n",
    "    else:\n",
    "        print('No exisiting q_table found. Starting fresh')\n",
    "        return {}\n",
    "\n",
    "def save_q_table(q_table):\n",
    "    data = {}\n",
    "    for key, value in q_table.items():\n",
    "        # JSON Doesn't Support Integer Keys, So Convert To A String\n",
    "        data[str(key)] = value\n",
    "    # 'w' means Write Mode\n",
    "    with open('q_table.json', 'w') as table_file:\n",
    "        # dump Writes The Contents Onto The File\n",
    "        json.dump(data, table_file, indent = 2)\n",
    "\n",
    "# Q-Learning Logic. Also A Form Of Reinforcement Learning Under Value-Based Methods\n",
    "# Exploration Rate. 0.3 Means 30% Of The Time, Explore. Other 70% Of The Time, Use Q-Table. Start High Then Decrease As AI Learns\n",
    "epsilon = 0.3\n",
    "# Learning Rate. 0.1 Means Adjust Q-Values By 10%. 0.01 Means Slow Learning. 0.99 Basically Means Forget What The AI Previously Learned\n",
    "alpha = 0.1\n",
    "# Discount Factor. Future Rewards vs Immediate Rewards. 0.0 Immediate Only. 1.0 Balances Future Rewards Equally to Immediate Rewards.\n",
    "gamma = 0.9\n",
    "\n",
    "# Current Game State Is None As There Is Nothing To Begin With\n",
    "previous_game_state = None\n",
    "\n",
    "# Used To Track Frames Specifically For Attacking\n",
    "action_counter = 0\n",
    "\n",
    "# Used To Determine What Action The AI Will Do\n",
    "current_action = 0\n",
    "\n",
    "# Load Existing Training. If Not, Starts A New Table To Train AI\n",
    "q_table = load_q_table()\n",
    "if q_table:\n",
    "    print(f\"Loaded previous training: {q_table}\")\n",
    "\n",
    "# Used To Track Most Recent p1_health. By Default, Health Is 144\n",
    "last_p1_health = 144\n",
    "last_p2_health = 144\n",
    "\n",
    "# Used For The First Two Seconds Of The Game Booting Up\n",
    "initial_frames = 0\n",
    "# Keeps Track Of Frames Per Second\n",
    "frames_passed = 0\n",
    "# Keeps Track Of What Match We're On\n",
    "match_number = 1\n",
    "# . . . Round Ended? . . .\n",
    "round_ended = False\n",
    "# . . . Round 1? Or Round 2? . . .\n",
    "round_number = 1\n",
    "# Used To Determine What Match We're On\n",
    "p1_rounds_won = 0\n",
    "p2_rounds_won = 0\n",
    "\n",
    "# \"while pyboy.tick()\" Is The Coding Version Of \"while pyboy is running\"\n",
    "while pyboy.tick():\n",
    "    # Disables Sound For The First Two Seconds\n",
    "    if initial_frames < 120:\n",
    "        pyboy.memory[0xFF26] = 0x00\n",
    "        initial_frames += 1\n",
    "    else:\n",
    "        # Don't Want The Frame Count Get Unnecessarily Humongous\n",
    "        initial_frames = 120\n",
    "\n",
    "    # Increases Frame Count\n",
    "    frames_passed += 1\n",
    "    # Increases Frame Count For Actions\n",
    "    action_counter += 1\n",
    "\n",
    "    # Chooses A Random Action Every 10 Frames\n",
    "    if action_counter == 10 and not round_ended:\n",
    "\n",
    "        # Just Gets The Current State Of The Game\n",
    "        current_game_state = get_game_state()\n",
    "\n",
    "        # Grabs Player Health\n",
    "        p1_health = pyboy.memory[P1_HEALTH_CHANNEL]\n",
    "        p2_health = pyboy.memory[P2_HEALTH_CHANNEL]\n",
    "\n",
    "        # Calculates The Reward Based On The Latest Action\n",
    "        if p1_health <= 144 and p2_health <= 144:\n",
    "            damage_dealt = last_p2_health - p2_health\n",
    "            damage_taken = last_p1_health - p1_health\n",
    "\n",
    "            # Updates Q-Table If It Has A Previous State (aka: not None)\n",
    "            if previous_game_state is not None:\n",
    "                # Creates A Reward Where More Damage Is Rewarded More. If Only Damage Was Taken, Then A Negative Reward\n",
    "                reward = (damage_dealt * 2) - damage_taken\n",
    "\n",
    "                # If We Haven't Seen The Previous State Before, Create It In The Table\n",
    "                if previous_game_state not in q_table:\n",
    "                    q_table[previous_game_state] = [0] * 4\n",
    "                # If We Haven't Seen The Current State Before, Create It In The Table\n",
    "                if current_game_state not in q_table:\n",
    "                    q_table[current_game_state] = [0] * 4\n",
    "\n",
    "                # 4 Lines Of Code Below Updates Q-Learning\n",
    "                # Grabs The Previous Value In The q_table\n",
    "                old_value = q_table[previous_game_state][current_action]\n",
    "                # Finds What The Best Value Of The Current State Is\n",
    "                next_max = max(q_table[current_game_state])\n",
    "                # The Bellman Equation!!!!!!!!!\n",
    "                # New Estimate = Old Estimate + Learning From Mistake\n",
    "                new_value = old_value + alpha * (reward + gamma * next_max - old_value)\n",
    "                # Updates q_table With New Learned Value\n",
    "                q_table[previous_game_state][current_action] = new_value\n",
    "                # What Basically Happened Above Is It Calculated What The Future Actions Will Lead To. So It's Using Multiple Rewards For The Most Optimal Final Reward\n",
    "\n",
    "            # Just Updates The Health\n",
    "            last_p1_health = p1_health\n",
    "            last_p2_health = p2_health\n",
    "            \n",
    "        # Choose Next Action To Do\n",
    "        # Explores\n",
    "        if random.random() < epsilon:\n",
    "            current_action = random.randint(0, 3)\n",
    "        # Uses Q-Table\n",
    "        else:\n",
    "            # Creates Values In q_table If Not Already In There\n",
    "            if current_game_state not in q_table:\n",
    "                q_table[current_game_state] = [0] * 4\n",
    "            # Finds Best Action By Finding Which Has Highest Value In q_table\n",
    "            current_action = q_table[current_game_state].index(max(q_table[current_game_state]))\n",
    "\n",
    "        # Action Activators\n",
    "        if current_action == 0:\n",
    "            pyboy.button_press('left')\n",
    "        elif current_action == 1:\n",
    "            pyboy.button_press('right')\n",
    "        elif current_action == 2:\n",
    "            pyboy.button_press('b')\n",
    "        elif current_action == 3:\n",
    "            pyboy.button_press('a')\n",
    "\n",
    "        # Remembers Current Game State For Later Use\n",
    "        previous_game_state = current_game_state\n",
    "\n",
    "    # Release Buttons\n",
    "    if action_counter == 15:\n",
    "        pyboy.button_release('left')\n",
    "        pyboy.button_release('right')\n",
    "        pyboy.button_release('b')\n",
    "        pyboy.button_release('a')\n",
    "        action_counter = 0\n",
    "    \n",
    "    # Because Of How Frequently pyboy.tick() Runs, It Results In 60 Frames Per Second, or 60 Ticks Per Second\n",
    "    if frames_passed == 60:\n",
    "        timer = pyboy.memory[TIMER_CHANNEL]\n",
    "        p1_health = pyboy.memory[P1_HEALTH_CHANNEL]\n",
    "        p2_health = pyboy.memory[P2_HEALTH_CHANNEL]\n",
    "\n",
    "        if not round_ended:\n",
    "            # Determines Who Won\n",
    "            if p1_health == 255:\n",
    "                print('PLAYER 2 WINS!', end='\\r')\n",
    "                p2_rounds_won += 1\n",
    "                round_ended = True\n",
    "                previous_game_state = None\n",
    "            elif p2_health == 255:\n",
    "                print('PLAYER 1 WINS!', end='\\r')\n",
    "                p1_rounds_won += 1\n",
    "                round_ended = True\n",
    "                previous_game_state = None\n",
    "\n",
    "        # Deactivates round_ended\n",
    "        if round_ended and p1_health == 144 and p2_health == 144:\n",
    "            round_number += 1\n",
    "            round_ended = False\n",
    "            \n",
    "        # Increases The Match Number Once A Player Has Won Twice\n",
    "        if p1_health == 144 and p2_health == 144 and (p1_rounds_won == 2 or p2_rounds_won == 2):\n",
    "            match_number += 1\n",
    "            p1_rounds_won = 0\n",
    "            p2_rounds_won = 0\n",
    "            round_number = 1\n",
    "\n",
    "\n",
    "        p1_distance = pyboy.memory[P1_DISTANCE_CHANNEL]\n",
    "        p2_distance = pyboy.memory[P2_DISTANCE_CHANNEL]\n",
    "        # Prints A Live Chart Of Stuff Happening\n",
    "        print(f\"Match: {match_number} | Round: {round_number} | Timer: {timer:2} | P1 Health: {p1_health:3} | P2 Health: {p2_health:3} | P1 Distance: {p1_distance} | P2 Distance: {p2_distance}\", end='\\r')\n",
    "        # Resets Frame Count \n",
    "        frames_passed = 0\n",
    "\n",
    "save_q_table(q_table)\n",
    "pyboy.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7e777-d728-4ad6-892a-b75ee71e5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff I Can Do To Improve AI\n",
    "# Learn Combos\n",
    "# Change The Distance Tracker To Also Know If On The Left or Right Side Of The Opponent To Then Know What Direction To Move\n",
    "# Be Able To Jump\n",
    "# Use Special Moves\n",
    "# Respond To Certain Moves For A Counter Attack/Combo/Block\n",
    "# Extra Reward Points For Winning\n",
    "# Detect What Match The AI Is On. Currently Just Adding A New Match Even If Constantly Stucky On Same Battle With A Fighter\n",
    "# Add Live Tracker Of Q-Table\n",
    "# Add Live Tracker Of Action Performed\n",
    "# Include Q-Table For Each Character In The Game (play style might differ between characters)\n",
    "# Adjust AI So It Learns What To Do At Its Distance Rather Than Me Telling It"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
